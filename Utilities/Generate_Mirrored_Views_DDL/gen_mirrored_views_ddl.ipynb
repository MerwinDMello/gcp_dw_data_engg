{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_contents_file(file_path, encoding_scheme='cp1252'):\n",
    "    inputfile = open(file_path, 'r', encoding=encoding_scheme)\n",
    "    return inputfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write file to local directory\n",
    "def write_file_local(path,file_data, write_mode='w'):\n",
    "    \n",
    "    with open(path, write_mode) as file:\n",
    "        file_string = file_data\n",
    "        file.write(file_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lob_config.json') as json_lob_config:\n",
    "    config = json.load(json_lob_config)\n",
    "\n",
    "lob = config['lob']\n",
    "project_id = config['project_id']\n",
    "input_path_folder = config['input_path_folder']\n",
    "output_path_folder = config['output_path_folder']\n",
    "input_core_tables_file = config['input_core_tables_file']\n",
    "merged_output_file = config['merged_output_file']\n",
    "sql_extension = config['sql_extension']\n",
    "datasets = config['datasets']\n",
    "\n",
    "parms_find_replace_list = [\n",
    "    {'search':'{{ params.param_pbs_core_dataset_name }}.','replace':'`hca-hin-curated-mirroring-td`.edwpbs.'},\n",
    "    {'search':'{{ params.param_pbs_base_views_dataset_name }}.','replace':'`hca-hin-prod-cur-parallon`.edwpbs_base_views_copy.'},\n",
    "    {'search':'{{ params.param_auth_base_views_dataset_name }}.','replace':'`hca-hin-prod-cur-parallon`.auth_base_views.'},\n",
    "    {'search':'{{ params.param_pbs_bqutil_fns_dataset_name }}.','replace':'`hca-hin-prod-cur-parallon`.bqutil_fns.'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql_files(sql_file_path):\n",
    "\n",
    "    client = bigquery.Client(project=project_id)\n",
    "    with open(sql_file_path, 'r') as sql_file:\n",
    "        file_name = os.path.basename(sql_file_path)\n",
    "        sql_query = sql_file.read()\n",
    "        try:         \n",
    "            client.query(sql_query, project=project_id, location='US').result()\n",
    "            logging.info(f\"SQL file {file_name} executed successfully.\")\n",
    "            print(f\"SQL file {file_name} executed successfully.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error executing SQL file {file_name}: {e}\")\n",
    "            print(f\"Error executing SQL file {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the DDLs for the tables from teradata \n",
    "def check_views_for_tables():\n",
    "    dt1 = datetime.now()\n",
    "\n",
    "    try:\n",
    "        \n",
    "        for dataset in datasets:\n",
    "            qualified_path = os.path.join(output_path_folder, lob.strip(), dataset)\n",
    "            print(qualified_path)\n",
    "            if os.path.exists(qualified_path):\n",
    "                shutil.rmtree(qualified_path, ignore_errors=True)\n",
    "            os.makedirs(qualified_path)\n",
    "\n",
    "        df = pd.read_csv(input_core_tables_file, index_col=None)\n",
    "\n",
    "        merged_output_file_path = f\"{merged_output_file}{sql_extension}\"\n",
    "        if os.path.exists(merged_output_file_path):\n",
    "            os.remove(merged_output_file_path)\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            table_name = str(row['table_id']).strip().lower()\n",
    "            file_name_search = f\"{table_name}{sql_extension}\"\n",
    "            for dataset in datasets:\n",
    "                input_file_path = os.path.join(input_path_folder, dataset, file_name_search)\n",
    "                if os.path.exists(input_file_path):\n",
    "                    file_contents = read_contents_file(input_file_path)\n",
    "                    output_file_path = f\"{output_path_folder}\\{lob.strip()}\\{dataset}\\{file_name_search}\"\n",
    "                    for i in range(len(parms_find_replace_list)):\n",
    "                        file_contents = file_contents.replace(parms_find_replace_list[i][\"search\"], parms_find_replace_list[i]['replace'])  \n",
    "                    write_file_local(output_file_path, file_contents)\n",
    "                    write_file_local(merged_output_file_path, file_contents, \"a\")\n",
    "\n",
    "        # print(\"Project ID : {}\".format(project_id))\n",
    "        \n",
    "        # execute_sql_files(qualified_filename_path)\n",
    "\n",
    "    except Exception as e1:\n",
    "        print(e1)\n",
    "        print(\"File Name : {}\".format(file_name_search))\n",
    "        pass\n",
    "    \n",
    "    dt2 = datetime.now()\n",
    "    print(dt2-dt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin of Processing\n",
      "Qualified_SQLS\\PBS\\edwpbs_base_views\n",
      "0:00:08.094898\n",
      "End of Processing\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin of Processing\")\n",
    "\n",
    "check_views_for_tables()\n",
    "\n",
    "print(\"End of Processing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
