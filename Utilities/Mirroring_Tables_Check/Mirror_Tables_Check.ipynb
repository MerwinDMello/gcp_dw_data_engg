{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !py -3 -m pip install --upgrade Jinja2==3.0.3\n",
    "# !py -3 -m pip install pandas\n",
    "# !py -3 -m pip install teradatasql\n",
    "# !py -3 -m pip install teradatasqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import os\n",
    "import json\n",
    "from jinjasql import JinjaSql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/td_config.json') as json_td_config:\n",
    "    config = json.load(json_td_config)\n",
    "\n",
    "USER_NAME = config['user_name']\n",
    "PASSWORD = config['pword']\n",
    "HOST_NAME = config['host_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_engine = sqlalchemy.create_engine('teradatasql://' + HOST_NAME + '/?user=' + USER_NAME + '&password=' + PASSWORD + '&logmech=KRB5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of file with table name and database name in csv file \n",
    "input_path = \"InputFiles\\\\mirror_tables_check.csv\"\n",
    "output_folder = \"OutputFiles\\\\\"\n",
    "output_file = 'mirrored_results.csv'\n",
    "output_path = f\"{output_folder}{output_file}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write file to local directory\n",
    "def write_file_local(path,file_data):\n",
    "    \n",
    "    with open(path, 'w') as file:\n",
    "        file_string = '\\n'.join(file_data)\n",
    "        file.write(file_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Mirror Table Check \n",
    "def run_mirror_table_check():\n",
    "    try:\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.mkdir(output_folder)\n",
    "        \n",
    "        file_df = pd.read_csv(input_path, index_col=None)\n",
    "        file_df.sort_values(by=['Database_Name','Table_Name'],inplace=True)\n",
    "        datasets = ','.join(f\"'{database}'\" for database in file_df.Database_Name.unique())\n",
    "\n",
    "        query = \"SELECT databasename as Database_Name, tablename as Table_Name, wherecond as Criteria, refreshappendcdc as Mirroring_Type FROM edw_pub_views.mirroring_status WHERE databasename IN ({});\".format(datasets)\n",
    "        table_df = pd.read_sql(query, td_engine)\n",
    "        table_df.sort_values(by=['Database_Name','Table_Name'],inplace=True)\n",
    "\n",
    "        combined_df = file_df.merge(table_df, how='outer', on=['Database_Name','Table_Name'], sort=True, indicator=True, validate=\"one_to_one\")\n",
    "\n",
    "        mirrored_status_list = []\n",
    "        mirrored_status_list.append(\"Dataset,Table,Status,Criteria,Mirroring_Type\")\n",
    "        # print(combined_df)\n",
    "        for idx in combined_df.index:\n",
    "            database = combined_df['Database_Name'][idx]\n",
    "            table = combined_df['Table_Name'][idx]\n",
    "            \n",
    "            match combined_df['_merge'][idx]:\n",
    "                case 'both':\n",
    "                    status = 'Mirrored'\n",
    "                    criteria = combined_df['Criteria'][idx]\n",
    "                    mirroring_type = combined_df['Mirroring_Type'][idx]                    \n",
    "                case 'right_only':\n",
    "                    status = 'Not Found in Analysis'\n",
    "                    criteria = combined_df['Criteria'][idx]\n",
    "                    mirroring_type = combined_df['Mirroring_Type'][idx]\n",
    "                case 'left_only':\n",
    "                    status = 'Not Mirrored'\n",
    "                    criteria = \"\"\n",
    "                    mirroring_type = \"\"\n",
    "\n",
    "            mirrored_status_list.append(f\"{database},{table},{status},{criteria},{mirroring_type}\")\n",
    "        \n",
    "        write_file_local(output_path, mirrored_status_list)\n",
    "\n",
    "    except Exception as e1:\n",
    "        print(e1)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Begin of Processing\")\n",
    "\n",
    "run_mirror_table_check()\n",
    "\n",
    "print(\"End of Processing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
