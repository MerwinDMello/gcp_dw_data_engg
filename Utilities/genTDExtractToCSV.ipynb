{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = 'KHU9683'\n",
    "pword = 'Zen18@dme'\n",
    "host_name='PARAEDWPROD.DW.MEDCITY.NET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_engine = sqlalchemy.create_engine('teradatasql://' + host_name + '/?user=' + user_name + '&password=' + pword + '&logmech=KRB5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def touch(path):\n",
    "    with open(path, 'a') as csvfile:\n",
    "        os.utime(path, None)\n",
    "        # close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write csvfile to local directory\n",
    "def write_csv_file(path, fields, data, write_mode=\"w\", delimiter=\",\", quote_char=\"\"):\n",
    "    \n",
    "    with open(path, write_mode, newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter=delimiter, quotechar=quote_char, quoting=csv.QUOTE_MINIMAL)\n",
    "        # csvwriter.writerow(fields)\n",
    "        csvwriter.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of file with table name and database name in csv file \n",
    "input_path = \"InputFiles\\\\copy_table_data.csv\"\n",
    "output_path_folder = \"OutputFiles\\\\TableData\\\\\"\n",
    "output_file_extension = \"csv\"\n",
    "v_chunksize = 100000\n",
    "write_mode = \"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the DDLs for the tables from teradata \n",
    "def gen_copy_table_data():\n",
    "        dt1 = datetime.now()\n",
    "        delimiter = ','\n",
    "        quote_char = '\"'\n",
    "        df = pd.read_csv(input_path, index_col=None)\n",
    "        run_date = (datetime.now()+timedelta(hours=-6)).strftime('%y%m%d')\n",
    "        if not os.path.exists(output_path_folder + run_date):\n",
    "            os.makedirs(output_path_folder + run_date)      \n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            try:\n",
    "                database_name = str(row['Database']).strip().lower()\n",
    "                table_name = str(row['Table']).strip().lower()\n",
    "\n",
    "                query = \"Select LOWER(TRIM(columnname)) AS columnname, UPPER(TRIM(columntype)) AS columntype \"\\\n",
    "                    \"From dbc.columnsV WHERE UPPER(DatabaseName) = '{}' AND UPPER(TableName) = '{}'\"\\\n",
    "                    \";\".format(database_name, table_name)\n",
    "                tablemeta_df = pd.read_sql(query, td_engine)\n",
    "\n",
    "                query = \"Select * From {}.{};\".format(database_name, table_name)\n",
    "\n",
    "                output_path = \"{}{}\\\\{}_{}.{}\".format(output_path_folder, run_date, table_name, run_date, output_file_extension)\n",
    "\n",
    "                touch(output_path)\n",
    "                \n",
    "                for results_df in pd.read_sql(query, td_engine, chunksize=v_chunksize):\n",
    "                \n",
    "                    # print(tablemeta_df[tablemeta_df[\"columnname\"] == \"sk_code\"])\n",
    "\n",
    "                    for column in results_df:\n",
    "                        column_name = str(results_df[column].name).lower()\n",
    "                        column_type = str(tablemeta_df[tablemeta_df['columnname']==column_name]['columntype'].values[0])\n",
    "                        # print(column_type)\n",
    "\n",
    "                        if column_type in ['CV', 'CF', 'BO', 'BF', 'BV']:\n",
    "                            # print(column_name)\n",
    "                            results_df[column] = results_df[column].str.encode(\"ascii\",\"ignore\").str.decode(\"ascii\")\n",
    "                            # results_df[column].replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
    "\n",
    "                    fields = list(results_df.columns)\n",
    "\n",
    "                    data = results_df.values.tolist()\n",
    "                    \n",
    "                    write_csv_file(output_path, fields, data, write_mode, delimiter, quote_char)\n",
    "\n",
    "            except Exception as e1:\n",
    "                print(e1)\n",
    "                print(\"Database : {}, Table : {}\".format(database_name,table_name))\n",
    "                pass\n",
    "        \n",
    "        dt2 = datetime.now()\n",
    "        print(dt2-dt1)\n",
    "        print(\"Tables for Copying Data : \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin of Processing\n",
      "0:15:58.097538\n",
      "Tables for Copying Data :  22\n",
      "End of Processing\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin of Processing\")\n",
    "\n",
    "gen_copy_table_data()\n",
    "\n",
    "print(\"End of Processing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
