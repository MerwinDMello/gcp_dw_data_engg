{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !py -3 -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "import logging\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write file to local directory\n",
    "def write_file_local(path,file_data):\n",
    "    \n",
    "    with open(path, 'w') as file:\n",
    "        file_string = file_data\n",
    "        file.write(file_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/lob_config.json') as json_lob_config:\n",
    "    config = json.load(json_lob_config)\n",
    "\n",
    "lob = config['lob']\n",
    "lob_lower = lob.lower().strip()\n",
    "domain_abbr = config['domain_abbr']\n",
    "core_dataset_list = config['core_dataset_list']\n",
    "\n",
    "regexp_subquery = re.compile(r\"(?:\"+'|'.join(core_dataset_list)+\")\\.([a-z|0-9|_]+)\",re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "jinja_template_path = config['jinja_template_path']\n",
    "jinja_extension = config['jinja_extension']\n",
    "yaml_extension = config['yaml_extension']\n",
    "output_parent_folder = config['output_parent_folder']\n",
    "integrate_meta_folder = config['integrate_meta_folder']\n",
    "integrate_meta_file_name = config['integrate_meta_file_name']\n",
    "dag_trigger_map_file_name = config['dag_trigger_map_file_name']\n",
    "dag_id_timings_file_name = config['dag_id_timings_file_name']\n",
    "dag_schedule_file_name = config['dag_schedule_file_name']\n",
    "\n",
    "domain_abbr_lower = domain_abbr.lower().strip()\n",
    "\n",
    "input_path = f\"{integrate_meta_folder}\\{integrate_meta_file_name}\"\n",
    "\n",
    "# df_dag_trigger_map = pd.read_csv(f\"{integrate_meta_folder}\\{dag_trigger_map_file_name}\", index_col=None)\n",
    "\n",
    "# df_dag_id_timings = pd.read_csv(f\"{integrate_meta_folder}\\{dag_id_timings_file_name}\", index_col=None)\n",
    "\n",
    "df_dag_schedule_info = pd.read_csv(f\"{integrate_meta_folder}\\{dag_schedule_file_name}\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the DDLs for the tables from teradata \n",
    "def gen_integrate_yaml():\n",
    "    dt1 = datetime.now()\n",
    "\n",
    "    integrate_yaml_path = f\"{output_parent_folder}\\{lob.strip()}\"\n",
    "    if os.path.exists(integrate_yaml_path):\n",
    "        shutil.rmtree(integrate_yaml_path, ignore_errors=True)\n",
    "    os.makedirs(integrate_yaml_path)\n",
    "\n",
    "    df = pd.read_csv(input_path, index_col=None)\n",
    "\n",
    "    db_type_param = \"sqlserver\"\n",
    "    env = Environment(loader = FileSystemLoader(jinja_template_path),   trim_blocks=True, lstrip_blocks=True)\n",
    "\n",
    "    prev_source_system = \"\"\n",
    "    prev_dag_suffix_id = \"\"\n",
    "    trigger_dag_param = \"\"\n",
    "    file_contents = \"integrate:\"\n",
    "    primary_table_name = \"\"\n",
    "    integrate_scripts = []\n",
    "    validation_scripts = []\n",
    "\n",
    "    cur_year = dt1.year\n",
    "    cur_month = dt1.month\n",
    "    cur_day = dt1.day\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "\n",
    "            integration_script = str(row['Integration_Script']).strip().lower()\n",
    "            source_system = str(row['Source']).strip().lower()\n",
    "            frequency = str(row['Frequency']).strip().lower()\n",
    "            dag_suffix_id = str(row['Dag_Suffix_ID']).strip().lower()\n",
    "            # sql_group_sequence = str(row['SQL_Group_Sequence']).strip().lower()\n",
    "            # job_name = str(row['Job_Name']).strip().lower()\n",
    "            validation_audit_sql_script_name = str(row['Validation_Audit_SQL_Script_Name']).strip().lower()\n",
    "            table_name = str(row['Table_Name']).strip().lower()\n",
    "            validation_script_present = str(row['Validation_Script_Present']).strip().lower()\n",
    "\n",
    "            if prev_source_system != source_system:\n",
    "                if index > 0:\n",
    "                    output_file_path = f\"{output_parent_folder}\\{lob.strip()}\\{prev_source_system}_integrate_dependency{yaml_extension}\"\n",
    "                    print(output_file_path)\n",
    "                    write_file_local(output_file_path, file_contents)\n",
    "\n",
    "            if prev_source_system != source_system or (prev_source_system == source_system and prev_dag_suffix_id != dag_suffix_id):\n",
    "                dag_id = f\"dag_integrate_{source_system}_{db_type_param}_{frequency}_{str(dag_suffix_id).zfill(2)}\"\n",
    "                # df_dag_trigger_map_match = df_dag_trigger_map[df_dag_trigger_map[\"Dag_Id\"]==dag_id]\n",
    "                df_dag_trigger_map_match = df_dag_schedule_info[df_dag_schedule_info[\"Dag_ID\"]==dag_id || df_dag_schedule_info[\"Execution_Type\"]==\"Triggerred\"]\n",
    "                if df_dag_trigger_map_match.empty:\n",
    "                    trigger_dag_param = []\n",
    "                else:\n",
    "                    trigger_dag_param = df_dag_trigger_map_match[\"Triggered_Dag_Id\"].tolist()\n",
    "\n",
    "                # df_dag_id_timings_match = df_dag_id_timings[df_dag_id_timings[\"Dag_ID\"]==dag_id]\n",
    "                df_dag_id_timings_match = df_dag_schedule_info[df_dag_schedule_info[\"Dag_ID\"]==dag_id || df_dag_schedule_info[\"Execution_Type\"]==\"Scheduled\"]\n",
    "                if df_dag_id_timings_match.empty:\n",
    "                    dag_schedule = \"None\"\n",
    "                else:\n",
    "                    dag_time = str(df_dag_id_timings_match[\"Time\"].iloc[0]).strip().lower()\n",
    "                    dag_frequency = str(df_dag_id_timings_match[\"Frequency\"].iloc[0]).strip().lower()\n",
    "                    dag_day_of_month = int(df_dag_id_timings_match[\"Day_of_Month\"].iloc[0]) if not math.isnan(df_dag_id_timings_match[\"Day_of_Month\"].iloc[0]) else np.nan\n",
    "                    dag_day_of_week = int(df_dag_id_timings_match[\"Day_of_Week\"].iloc[0]) if not math.isnan(df_dag_id_timings_match[\"Day_of_Week\"].iloc[0]) else np.nan\n",
    "\n",
    "                    hour_of_day = dag_time.split(\":\")[0] if len(dag_time.split(\":\")) > 1 else dag_time\n",
    "                    if hour_of_day != \"*\":\n",
    "                        hour_of_day = int(hour_of_day)\n",
    "\n",
    "                    minute_of_day = dag_time.split(\":\")[1] if len(dag_time.split(\":\")) > 1 else '*'\n",
    "                    if minute_of_day != \"*\":\n",
    "                        minute_of_day = int(minute_of_day)\n",
    "\n",
    "                    if dag_frequency == \"monthly\":\n",
    "                        day_of_month = dag_day_of_month\n",
    "                    else:\n",
    "                        day_of_month = \"*\"\n",
    "\n",
    "                    if dag_frequency == \"weekly\":\n",
    "                        day_of_week = dag_day_of_week\n",
    "                    else:\n",
    "                        day_of_week = \"*\"\n",
    "\n",
    "                    dag_schedule = f\"{minute_of_day} {hour_of_day} {day_of_month} * {day_of_week}\"\n",
    "\n",
    "                replace_params = {\n",
    "                    \"source_system_param\": f\"{source_system}\",\n",
    "                    \"frequency_param\": f\"{frequency}\",\n",
    "                    \"dag_id_param\": f\"{dag_suffix_id}\",\n",
    "                    \"year_param\": f\"{cur_year}\",\n",
    "                    \"month_param\": f\"{cur_month}\",\n",
    "                    \"day_param\": f\"{cur_day}\",\n",
    "                    \"schedule_param\": f\"{dag_schedule}\",\n",
    "                    \"db_type_param\": f\"{db_type_param}\",\n",
    "                    \"trigger_dag_param\": f\"{trigger_dag_param}\"\n",
    "                }\n",
    "                template = env.get_template(f\"integrate_header{jinja_extension}\")\n",
    "                if prev_source_system != source_system and prev_dag_suffix_id != dag_suffix_id:\n",
    "                    file_contents = \"integrate:\" + \"\\n\"\n",
    "                file_contents = file_contents + template.render(replace_params) + \"\\n\"\n",
    "            \n",
    "            core_table_find = regexp_subquery.search(table_name)\n",
    "            if core_table_find is None:\n",
    "                primary_table_name = \"\"\n",
    "                script_rec = {\"script_name\": integration_script}\n",
    "                integrate_scripts.append(script_rec)\n",
    "            else:\n",
    "                primary_table_name = core_table_find.groups()[0].lower()\n",
    "                replace_params = {\n",
    "                    \"table_param\": f\"{primary_table_name}\"\n",
    "                }\n",
    "                template = env.get_template(f\"integrate_dependency{jinja_extension}\")\n",
    "                file_contents = file_contents + template.render(replace_params) + \"\\n\"\n",
    "\n",
    "                script_rec = {\"script_name\": integration_script}\n",
    "                integrate_scripts.append(script_rec)\n",
    "                replace_params = {\n",
    "                    \"script_file_list\": integrate_scripts\n",
    "                }\n",
    "                template = env.get_template(f\"integrate_sql{jinja_extension}\")\n",
    "                file_contents = file_contents + template.render(replace_params)\n",
    "                integrate_scripts = []\n",
    "\n",
    "                if validation_script_present.lower() == 'yes':\n",
    "                    script_rec = {\"script_name\": validation_audit_sql_script_name}\n",
    "                else:\n",
    "                    script_rec = {\"script_name\": 'NONE'}\n",
    "                validation_scripts.append(script_rec)\n",
    "                replace_params = {\n",
    "                    \"validation_file_list\": validation_scripts\n",
    "                }\n",
    "                template = env.get_template(f\"integrate_validation{jinja_extension}\")\n",
    "                file_contents = file_contents + template.render(replace_params)\n",
    "                validation_scripts = []\n",
    "                       \n",
    "            prev_source_system = source_system\n",
    "            prev_dag_suffix_id = dag_suffix_id\n",
    "\n",
    "            if index == len(df) - 1:\n",
    "                output_file_path = f\"{output_parent_folder}\\{lob.strip()}\\{prev_source_system}_integrate_dependency{yaml_extension}\"\n",
    "                print(output_file_path)\n",
    "                write_file_local(output_file_path, file_contents)\n",
    "\n",
    "        except Exception as e1:\n",
    "            print(e1)\n",
    "            pass\n",
    "    \n",
    "    dt2 = datetime.now()\n",
    "    print(dt2-dt1)\n",
    "\n",
    "    print(\"Record Count : \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin of Processing\n",
      "LOB\\CR\\navadhoc_integrate_dependency.yaml\n",
      "LOB\\CR\\varianedw_integrate_dependency.yaml\n",
      "LOB\\CR\\metriq_integrate_dependency.yaml\n",
      "0:00:00.222020\n",
      "Record Count :  150\n",
      "End of Processing\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin of Processing\")\n",
    "\n",
    "gen_integrate_yaml()\n",
    "\n",
    "print(\"End of Processing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
