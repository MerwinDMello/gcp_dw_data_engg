{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script_dir = os.path.dirname(__file__)\n",
    "script_dir = os.path.abspath('')\n",
    "util_dir = os.path.join(script_dir, '..', 'Common_Utils')\n",
    "sys.path.append(util_dir)\n",
    "import file_utilities as futil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r\"..\\Files\\Input_Files\\Table_Column_Info.csv\"\n",
    "output_path = \"..\\Files\\Output_Files\\Table_DDL\"\n",
    "contents = futil.read_file(input_path)\n",
    "futil.make_directory_if_not_exists(output_path)\n",
    "\n",
    "output_content_list = []\n",
    "table_name = ''\n",
    "column_name = ''\n",
    "data_type = ''\n",
    "header_rec = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_sql_file(table_name, output_content_list):\n",
    "        output_full_path = f\"{output_path}\\{table_name}.sql\"\n",
    "        sqlfile_contents = '\\n'.join(output_content_list)\n",
    "        futil.write_file(output_full_path, sqlfile_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate individual ddl files with parameterization\n",
    "dt1 = datetime.now()\n",
    "lines = contents.split(\"\\n\")\n",
    "for index, line in enumerate(lines):\n",
    "    if line.strip() == '' or (line.strip() != '' and index == 0 and header_rec == True) :\n",
    "        continue\n",
    "    else:\n",
    "        fields = line.split(\",\")\n",
    "        if (table_name != fields[0].strip().lower()):\n",
    "            if table_name != '':\n",
    "                output_content_list.append(');')\n",
    "                write_sql_file(table_name, output_content_list)\n",
    "\n",
    "            output_content_list = []\n",
    "            table_name = fields[0].strip().lower()\n",
    "            output_content_list.append('CREATE TABLE IF NOT EXISTS {{ params.param_stage_dataset_name }}.' + table_name)\n",
    "            output_content_list.append('(')\n",
    "        \n",
    "        column_name = fields[1].strip().lower()\n",
    "        data_type = fields[2].strip().lower()\n",
    "        if column_name == 'group': # Keywords needs to be in back ticks\n",
    "            column_name = f'`{column_name}`'\n",
    "        output_content_list.append('\\t' + column_name + ' ' + data_type + ',')\n",
    "\n",
    "if table_name != '':\n",
    "    output_content_list.append(');')\n",
    "    write_sql_file(table_name, output_content_list)\n",
    "\n",
    "dt2 = datetime.now()\n",
    "print(dt2-dt1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
